{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd8cc21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\oumaima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\oumaima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\oumaima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premières lignes du DataFrame :\n",
      "   tweet_id     author_id  inbound                      created_at  \\\n",
      "0    119237        105834     True  Wed Oct 11 06:55:44 +0000 2017   \n",
      "1    119238  ChaseSupport    False  Wed Oct 11 13:25:49 +0000 2017   \n",
      "2    119239        105835     True  Wed Oct 11 13:00:09 +0000 2017   \n",
      "3    119240  VirginTrains    False  Tue Oct 10 15:16:08 +0000 2017   \n",
      "4    119241        105836     True  Tue Oct 10 15:17:21 +0000 2017   \n",
      "\n",
      "                                                text response_tweet_id  \\\n",
      "0  @AppleSupport causing the reply to be disregar...            119236   \n",
      "1  @105835 Your business means a lot to us. Pleas...               NaN   \n",
      "2  @76328 I really hope you all change but I'm su...            119238   \n",
      "3  @105836 LiveChat is online at the moment - htt...            119241   \n",
      "4  @VirginTrains see attached error message. I've...            119243   \n",
      "\n",
      "   in_response_to_tweet_id  \n",
      "0                      NaN  \n",
      "1                 119239.0  \n",
      "2                      NaN  \n",
      "3                 119242.0  \n",
      "4                 119240.0  \n",
      "\n",
      "DataFrame avec les colonnes 'tweet_id', 'text' et 'text_cleaned' :\n",
      "   tweet_id                                               text  \\\n",
      "0    119237  @AppleSupport causing the reply to be disregar...   \n",
      "1    119238  @105835 Your business means a lot to us. Pleas...   \n",
      "2    119239  @76328 I really hope you all change but I'm su...   \n",
      "3    119240  @105836 LiveChat is online at the moment - htt...   \n",
      "4    119241  @VirginTrains see attached error message. I've...   \n",
      "\n",
      "                                        text_cleaned  \n",
      "0  applesupport caus repli disregard tap notif ke...  \n",
      "1  105835 busi mean lot u plea dm name zip code a...  \n",
      "2          76328 realli hope chang im sure wont dont  \n",
      "3  105836 livechat onlin moment httpstcosy94vtu8k...  \n",
      "4  virgintrain see attach error messag ive tri le...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "# Téléchargement des ressources NLTK nécessaires\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Chargement des données depuis le fichier CSV\n",
    "df = pd.read_csv('sample.csv')\n",
    "\n",
    "# Affichage des premières lignes du DataFrame\n",
    "print(\"Premières lignes du DataFrame :\")\n",
    "print(df.head())\n",
    "\n",
    "# Fonction de nettoyage du texte\n",
    "def clean_text(text):\n",
    "    # Mise en minuscules\n",
    "    text = text.lower()\n",
    "    # Suppression des ponctuations\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Suppression des mots vides\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "    # Stemming\n",
    "    porter = PorterStemmer()\n",
    "    stemmed_text = [porter.stem(word) for word in filtered_text]\n",
    "    # Lemmatisation\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_text = [lemmatizer.lemmatize(word) for word in stemmed_text]\n",
    "    return ' '.join(lemmatized_text)\n",
    "\n",
    "# Nettoyage du texte dans la colonne 'text' et création de la colonne 'text_cleaned'\n",
    "df['text_cleaned'] = df['text'].apply(clean_text)\n",
    "\n",
    "# Affichage du DataFrame avec les colonnes 'tweet_id', 'text' et 'text_cleaned'\n",
    "cleaned_df = df[['tweet_id', 'text', 'text_cleaned']]\n",
    "print(\"\\nDataFrame avec les colonnes 'tweet_id', 'text' et 'text_cleaned' :\")\n",
    "print(cleaned_df.head())\n",
    "\n",
    "# Sauvegarde du DataFrame nettoyé dans un nouveau fichier CSV\n",
    "cleaned_df.to_csv('cleaned_customer_support_tweets.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdc3dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
